{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /Users/angelachow/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from num2words import num2words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from autocorrect import Speller\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from translate import translator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('rslp')\n",
    "\n",
    "# dataset visibility\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    for word in text:\n",
    "        if word in stopwords.words('portuguese'):\n",
    "            text.remove(word)\n",
    "    return text\n",
    "\n",
    "stemmer = RSLPStemmer()\n",
    "spell = Speller('pt')\n",
    "\n",
    "def spell_and_stem_words(text):\n",
    "    for i in range(len(text)):\n",
    "        text[i] = stemmer.stem(spell(text[i]))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final dataframe\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all datasets\n",
    "\n",
    "# orders dataset\n",
    "orders = pd.read_csv('data/olist_orders_dataset.csv')\n",
    "\n",
    "# order items dataset\n",
    "items = pd.read_csv('data/olist_order_items_dataset.csv')\n",
    "\n",
    "# sellers dataset\n",
    "sellers = pd.read_csv('data/olist_sellers_dataset.csv')\n",
    "\n",
    "# sellers dataset\n",
    "customers = pd.read_csv('data/olist_customers_dataset.csv')\n",
    "\n",
    "# reviews dataset\n",
    "reviews = pd.read_csv('data/olist_order_reviews_dataset.csv')\n",
    "\n",
    "# products dataset\n",
    "products = pd.read_csv('data/olist_products_dataset.csv')\n",
    "\n",
    "# sellers dataset\n",
    "payments = pd.read_csv('data/olist_order_payments_dataset.csv')\n",
    "\n",
    "# categories dataset\n",
    "categories = pd.read_csv('data/product_category_name_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orders\n",
    "\n",
    "df = df.merge(customers, on='customer_id', how='left')\n",
    "df = df.merge(payments, on='order_id', how='left')\n",
    "df = df.merge(reviews, on='order_id', how='left')\n",
    "\n",
    "df = df.merge(items, on='order_id', how='left')\n",
    "df = df.merge(sellers, on='seller_id', how='left')\n",
    "df = df.merge(products, on='product_id', how='left')\n",
    "df = df.merge(categories, on='product_category_name', how='left')\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/merged_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.info()\n",
    "customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust = customers[\"customer_unique_id\"].nunique()\n",
    "print(cust, \"unique customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = customers[\"customer_city\"].nunique()\n",
    "c1 = customers.groupby('customer_city')['customer_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",cities,\"unique cities in the dataset. The Top 10 cities based on customers_id are:\")\n",
    "c2 = c1.head(10)\n",
    "print(c2)\n",
    "print(\"\\nTop 10 cities covers\", round(c2.sum()/customers.shape[0]*100,1),\"percent of all the orders.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "c2.plot(kind=\"bar\",rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = customers[\"customer_state\"].nunique()\n",
    "c1 = customers.groupby('customer_state')['customer_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",cities,\"unique states in the dataset. The Top 5 states are:\")\n",
    "c2 = c1.head(5)\n",
    "print(c2)\n",
    "print(\"\\nTop 10 states covers\", round(c2.sum()/customers.shape[0]*100,1),\"percent of all the orders.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "c2.plot(kind=\"bar\",rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.info()\n",
    "customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_mod = orders.copy()\n",
    "orders_mod[\"order_purchase_timestamp\"] = pd.to_datetime(orders[\"order_purchase_timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "orders_mod[\"order_delivered_carrier_date\"] = pd.to_datetime(orders[\"order_delivered_carrier_date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "orders_mod[\"order_delivered_customer_date\"] = pd.to_datetime(orders[\"order_delivered_customer_date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "orders_mod[\"order_estimated_delivery_date\"] = pd.to_datetime(orders[\"order_estimated_delivery_date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "orders_mod.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Viz on when purchases are made during period in dataset.\n",
    "counts = orders_mod.set_index(\"order_purchase_timestamp\").groupby(pd.Grouper(freq='D')).count()\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.gca()\n",
    "counts.plot(y = \"order_id\", use_index=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Identifies orderstatus distribution\n",
    "orderstatus = orders[\"order_status\"].nunique()\n",
    "o1 = orders.groupby('order_status')['customer_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",orderstatus,\"unique order_status in the dataset.\")\n",
    "o2 = o1.head(8)\n",
    "print(o2)\n",
    "o3 = o1.head(1)\n",
    "print(\"\\nDelivered status covers\", round(o3.sum()/orders.shape[0]*100,1),\"percent of all the orders.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   review_id                100000 non-null  object\n",
      " 1   order_id                 100000 non-null  object\n",
      " 2   review_score             100000 non-null  int64 \n",
      " 3   review_comment_title     11715 non-null   object\n",
      " 4   review_comment_message   41753 non-null   object\n",
      " 5   review_creation_date     100000 non-null  object\n",
      " 6   review_answer_timestamp  100000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parab√©ns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN  2018-01-18 00:00:00   \n",
       "1                                                NaN  2018-03-10 00:00:00   \n",
       "2                                                NaN  2018-02-17 00:00:00   \n",
       "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4  Parab√©ns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.info()\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id                      0\n",
       "order_id                       0\n",
       "review_score                   0\n",
       "review_comment_title       88285\n",
       "review_comment_message     58247\n",
       "review_creation_date           0\n",
       "review_answer_timestamp        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine how many missing data instances\n",
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address missing data - we can see that there is a review score but not necessarily a comment or a title. Should we make it \"none?\"\n",
    "\n",
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.info()\n",
    "items.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellerinfo = items[\"seller_id\"].nunique()\n",
    "o1 = items.groupby('seller_id')['order_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",items,\"unique items in the dataset.\")\n",
    "o2 = o1.head(10)\n",
    "print(o2)\n",
    "\n",
    "print(\"\\nTop 10 items covers\", round(o2.sum()/orders.shape[0]*100,1),\"percent of all the orders.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers.info()\n",
    "sellers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellerstatus = sellers[\"seller_id\"].nunique()\n",
    "o1 = sellers.groupby('seller_city')['seller_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",sellerstatus,\"unique sellers in the dataset.\")\n",
    "o2 = o1.head(8)\n",
    "print(o2)\n",
    "\n",
    "print(\"\\nTop Seller by city covers\", round(o2.sum()/orders.shape[0]*100,1),\"percent of all the sellers.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellerstatus = sellers[\"seller_id\"].nunique()\n",
    "o1 = sellers.groupby('seller_state')['seller_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",sellerstatus,\"unique sellers in the dataset.\")\n",
    "o2 = o1.head(8)\n",
    "print(o2)\n",
    "\n",
    "print(\"\\nTop Sellers by state represents\", round(o2.sum()/orders.shape[0]*100,1),\"percent of all the sellers.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.info()\n",
    "products.isnull().sum()\n",
    "# need to fix missing data 610 is the same entry but missing description. 2 items also missing (1 competely missing all except ID\n",
    "#other one is just missing weight, lenght, height, width) Dtypes changed from float64 to object as a result of replacing NA\n",
    "products[\"product_category_name\"].fillna(\"None\", inplace = True)\n",
    "products[\"product_name_lenght\"].fillna(\"None\", inplace = True)\n",
    "products[\"product_description_lenght\"].fillna(\"None\", inplace = True)\n",
    "products[\"product_photos_qty\"].fillna(\"None\", inplace = True)\n",
    "products[\"product_weight_g\"].fillna(\"0\", inplace = True)\n",
    "products[\"product_length_cm\"].fillna(\"0\", inplace = True)\n",
    "products[\"product_height_cm\"].fillna(\"0\", inplace = True)\n",
    "products[\"product_width_cm\"].fillna(\"0\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_product=df.groupby('product_category_name_english').aggregate({'order_id':'count'}).rename(columns={'order_id':'order_count'}).sort_values(by='order_count',ascending=False).reset_index()\n",
    "most_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualising top 10 most bought product categories:\n",
    "sns.barplot(x='product_category_name_english',y='order_count',data=most_product[:10],color=\"green\")\n",
    "plt.xlabel(\"Product Category\")\n",
    "plt.ylabel(\"Number of orders\")\n",
    "plt.title(\"Most bought product categories\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodcat= df[\"product_id\"].nunique()\n",
    "o1 = df.groupby('product_category_name_english')['product_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",prodcat,\"unique products in the dataset.\")\n",
    "o2 = o1.head(10)\n",
    "print(o2)\n",
    "\n",
    "print(\"\\nTop 10 Products by category represent\", round(o2.sum()/orders.shape[0]*100,1),\"percent of all the products.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments.info()\n",
    "payments.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.info()\n",
    "categories.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/angelachow/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/angelachow/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to work with only reviews dataset\n",
    "reviews = reviews.dropna()\n",
    "#reviews.head(100)\n",
    "\n",
    "reviews_only = reviews[reviews['review_score'] == 1]\n",
    "reviews_only = reviews_only['review_comment_message']\n",
    "# replace numbers of words\n",
    "reviews_only = reviews_only.apply(lambda t: re.sub(r\"(\\d+)\", lambda x: num2words(int(x.group(0))), t))\n",
    "# replace special characters\n",
    "reviews_only = reviews_only.apply(lambda t: re.sub('[^A-z√Ä-√∫\\s]/gi', ' ', t))\n",
    "# make all letters in a lower case\n",
    "reviews_only = reviews_only.apply(lambda t: t.lower())\n",
    "\n",
    "# tokenize text and remove stop words\n",
    "tokenized_reviews = reviews_only.apply(lambda t: word_tokenize(t))\n",
    "tokenized_reviews = tokenized_reviews.apply(lambda t: remove_stop_words(t))\n",
    "\n",
    "# spell check and stemming\n",
    "tokenized_reviews = tokenized_reviews.apply(lambda t: spell_and_stem_words(t))\n",
    "\n",
    "tokenized_reviews.head(100)\n",
    "\n",
    "reviews_text = tokenized_reviews.apply(lambda t: \" \".join(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix\n",
    "# creating the feature matrix\n",
    "matrix = CountVectorizer(max_features=1000, ngram_range=(2, 4))\n",
    "X = matrix.fit_transform(reviews_text).toarray()\n",
    "matrix.vocabulary_\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "\n",
    "a = reviews.iloc[201:400]\n",
    "translator = Translator()\n",
    "translator.raise_Exception = True\n",
    "reviews['English']=a['review_comment_message'].apply(translator.translate, src='pt', dest='en').apply(getattr, args=('text',))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_low = reviews[reviews['review_score'] == 1]\n",
    "reviews_low['English'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on 31615: veio faltando uma carteira e querendo saber como vai fica \n",
      "Unexpected status code \"429\" from ('translate.google.com',)\n",
      "pausing for 1min...\n",
      "trying again...\n",
      "Success! Moving on.\n",
      "Error on 31735: Foto diferente do produto, quero a troca ou a devolu√ß√£o do dinheiro\n",
      "Unexpected status code \"429\" from ('translate.google.com',)\n",
      "pausing for 1min...\n",
      "trying again...\n",
      "Success! Moving on.\n",
      "Error on 31760: Produto de baixa qualidade, na foto engana bem, bota esquerdo n√£o tem fun√ß√£o, o digital somente funciona se vc aperta um dos dois bot√µes da direita e logo apaga, instru√ß√£o em ingl√™s e chin√™s. \n",
      "Unexpected status code \"429\" from ('translate.google.com',)\n",
      "pausing for 1min...\n",
      "trying again...\n",
      "Success! Moving on.\n",
      "Error on 31877: Comprei dois filtros e a embalagem chegou com apenas um filtro... E o outro?\n",
      "Unexpected status code \"429\" from ('translate.google.com',)\n",
      "pausing for 1min...\n",
      "trying again...\n",
      "Success! Moving on.\n",
      "Error on 32024: Comprei duas cadeiras, uma o assento √± encaixa corretamente e a outra veio sem as borrachinhas para acabamento\n",
      "Unexpected status code \"429\" from ('translate.google.com',)\n",
      "pausing for 1min...\n",
      "trying again...\n",
      "Success! Moving on.\n",
      "Error on 32364: Infelizmente tive um problema com o aparelho,e o mesmo ter√° que ser feito troca.\n",
      "Unexpected status code \"429\" from ('translate.google.com',)\n",
      "pausing for 1min...\n",
      "trying again...\n",
      "Success! Moving on.\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "import time\n",
    "\n",
    "translator = Translator()\n",
    "translator.raise_Exception = True\n",
    "\n",
    "#mini-batch loop. Loops 200 at a time. Hit failures with the translate API, switched to the slow iterrows loop below\n",
    "#for i in range(0, len(reviews_low), 200): \n",
    "    #print(i)\n",
    "    #a = reviews_low.iloc[i:i+199]\n",
    "    #reviews_low['English']=a['review_comment_message'].apply(translator.translate, src='pt', dest='en').apply(getattr, args=('text',))\n",
    "\n",
    "# row by row to handle when API limits are hit...not the best performance...can probably add the try/except to the mini-batch above for better performance, assuming it calls the google API in bulk\n",
    "for i, row in reviews_low.iterrows():\n",
    "    # Skip rows that were successful from previous attempts\n",
    "    # Blank text also seems to throw an error in the translator\n",
    "    if pd.isnull(row['English']) and not pd.isnull(row['review_comment_message']) and row['review_comment_message'].strip() != '':\n",
    "        try:\n",
    "            #getattr is to retrieve the object value for 'text', returns None if 'text' is not in the object\n",
    "            reviews_low.at[i, 'English'] = getattr(translator.translate(row['review_comment_message'], src='pt', dest='en'), 'text')\n",
    "        # Most likely the 429 status code error from too many attempts\n",
    "        except Exception as e:\n",
    "            print('Error on {}: {}'.format(i, row['review_comment_message']))\n",
    "            print(e)\n",
    "            print('pausing for 1min...')\n",
    "            time.sleep(60)\n",
    "            print('trying again...')\n",
    "            reviews_low.at[i, 'English'] = getattr(translator.translate(row['review_comment_message'], src='pt', dest='en'), 'text')\n",
    "            print('Success! Moving on.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(reviews)\n",
    "reviews_low.to_csv(\"reviews_low.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=reviews.iloc[201:400]\n",
    "translator = Translator()\n",
    "translator.raise_Exception = True\n",
    "reviews['English']=a['review_comment_message'].apply(translator.translate, src='pt', dest='en').apply(getattr, args=('text',))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              review_id                          order_id  \\\n",
      "9      8670d52e15e00043ae7de4c01cc2fe06  b9bf720beb4ab3728760088589c62129   \n",
      "15     3948b09f7c818e2d86c9a546758b2335  e51478e7e277a83743b6f9991dbfa3fb   \n",
      "19     373cbeecea8286a2b66c97b1b157ec46  583174fbe37d3d5f0d6661be3aad1786   \n",
      "22     d21bbc789670eab777d27372ab9094cc  4fc44d78867142c627497b60a7e0228a   \n",
      "34     c92cdd7dd544a01aa35137f901669cdf  37e7875cdce5a9e5b3a692971f370151   \n",
      "...                                 ...                               ...   \n",
      "99962  47e0954e156dac6512c25c6d2ecc1c66  16cbf959cfdb88c47ee2a29303547ec2   \n",
      "99967  0e7bc73fde6782891898ea71443f9904  bd78f91afbb1ecbc6124974c5e813043   \n",
      "99971  58be140ccdc12e8908ff7fd2ba5c7cb0  0ebf8e35b9807ee2d717922d5663ccdb   \n",
      "99972  51de4e06a6b701cb2be47ea0e689437b  b7467ae483dbe956fe9acdf0b1e6e3f4   \n",
      "99975  2ee221b28e5b6fceffac59487ed39348  f2d12dd37eaef72ed7b1186b2edefbcd   \n",
      "\n",
      "       review_score       review_comment_title  \\\n",
      "9                 4                  recomendo   \n",
      "15                5            Super recomendo   \n",
      "19                1    N√£o chegou meu produto    \n",
      "22                5                      √ìtimo   \n",
      "34                4                 Muito bom.   \n",
      "...             ...                        ...   \n",
      "99962             5               Nota m√°xima!   \n",
      "99967             4                          üëç   \n",
      "99971             5         muito bom produto    \n",
      "99972             3  N√£o foi entregue o pedido   \n",
      "99975             2             Foto enganosa    \n",
      "\n",
      "                                  review_comment_message review_creation_date  \\\n",
      "9      aparelho eficiente. no site a marca do aparelh...  2018-05-22 00:00:00   \n",
      "15     Vendedor confi√°vel, produto ok e entrega antes...  2018-05-23 00:00:00   \n",
      "19                                               P√©ssimo  2018-08-15 00:00:00   \n",
      "22                                          Loja nota 10  2018-07-10 00:00:00   \n",
      "34     Recebi exatamente o que esperava. As demais en...  2018-06-07 00:00:00   \n",
      "...                                                  ...                  ...   \n",
      "99962  Muito obrigado,\\r\\n\\r\\nExcelente atendimento,b...  2018-05-22 00:00:00   \n",
      "99967                                          Aprovado!  2018-07-04 00:00:00   \n",
      "99971  Ficamos muito satisfeitos com o produto, atend...  2018-06-30 00:00:00   \n",
      "99972  Bom dia \\r\\nDas 6 unidades compradas s√≥ recebi...  2018-06-05 00:00:00   \n",
      "99975  Foto muito diferente principalmente a graninha...  2018-03-28 00:00:00   \n",
      "\n",
      "      review_answer_timestamp English  \n",
      "9         2018-05-23 16:45:47     NaN  \n",
      "15        2018-05-24 03:00:01     NaN  \n",
      "19        2018-08-15 04:10:37     NaN  \n",
      "22        2018-07-11 14:10:25     NaN  \n",
      "34        2018-06-09 18:44:02     NaN  \n",
      "...                       ...     ...  \n",
      "99962     2018-05-23 00:51:43     NaN  \n",
      "99967     2018-07-05 00:25:13     NaN  \n",
      "99971     2018-07-02 23:09:35     NaN  \n",
      "99972     2018-06-06 10:52:19     NaN  \n",
      "99975     2018-05-25 01:23:26     NaN  \n",
      "\n",
      "[9986 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "phrases = pd.DataFrame()\n",
    "phrases['phrases'] = matrix.get_feature_names()\n",
    "\n",
    "#phrases['translation']= phrases.apply(lambda t: translator('pt', 'en', str(t)))\n",
    "\n",
    "#phrases\n",
    "\n",
    "translator('pt', 'en', 'vei quebr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
