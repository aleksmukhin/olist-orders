{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports and Configurations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from num2words import num2words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from autocorrect import Speller\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from translate import translator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('rslp')\n",
    "\n",
    "# dataset visibility\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package rslp to /Users/angelachow/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def remove_stop_words(text):\n",
    "    for word in text:\n",
    "        if word in stopwords.words('english'):\n",
    "            text.remove(word)\n",
    "    return text\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "spell = Speller('en')\n",
    "\n",
    "def spell_and_stem_words(text):\n",
    "    for i in range(len(text)):\n",
    "        text[i] = stemmer.stem(spell(text[i]))\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Joining dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "#final dataframe\n",
    "df = pd.DataFrame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# read all datasets\n",
    "\n",
    "# orders dataset\n",
    "orders = pd.read_csv('data/olist_orders_dataset.csv')\n",
    "\n",
    "# order items dataset\n",
    "items = pd.read_csv('data/olist_order_items_dataset.csv')\n",
    "\n",
    "# sellers dataset\n",
    "sellers = pd.read_csv('data/olist_sellers_dataset.csv')\n",
    "\n",
    "# sellers dataset\n",
    "customers = pd.read_csv('data/olist_customers_dataset.csv')\n",
    "\n",
    "# reviews dataset\n",
    "reviews = pd.read_csv('data/olist_order_reviews_dataset.csv')\n",
    "\n",
    "# products dataset\n",
    "products = pd.read_csv('data/olist_products_dataset.csv')\n",
    "\n",
    "# sellers dataset\n",
    "payments = pd.read_csv('data/olist_order_payments_dataset.csv')\n",
    "\n",
    "# categories dataset\n",
    "categories = pd.read_csv('data/product_category_name_translation.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "df = orders\n",
    "\n",
    "df = df.merge(customers, on='customer_id', how='left')\n",
    "df = df.merge(payments, on='order_id', how='left')\n",
    "df = df.merge(reviews, on='order_id', how='left')\n",
    "\n",
    "df = df.merge(items, on='order_id', how='left')\n",
    "df = df.merge(sellers, on='seller_id', how='left')\n",
    "df = df.merge(products, on='product_id', how='left')\n",
    "df = df.merge(categories, on='product_category_name', how='left')\n",
    "\n",
    "#df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "df.to_csv('data/merged_dataset.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Customers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "customers.info()\n",
    "customers.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cust = customers[\"customer_unique_id\"].nunique()\n",
    "print(cust, \"unique customers\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cities = customers[\"customer_city\"].nunique()\n",
    "c1 = customers.groupby('customer_city')['customer_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",cities,\"unique cities in the dataset. The Top 10 cities based on customers_id are:\")\n",
    "c2 = c1.head(10)\n",
    "print(c2)\n",
    "print(\"\\nTop 10 cities covers\", round(c2.sum()/customers.shape[0]*100,1),\"percent of all the orders.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "c2.plot(kind=\"bar\",rot=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "state = customers[\"customer_state\"].nunique()\n",
    "c1 = customers.groupby('customer_state')['customer_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",cities,\"unique states in the dataset. The Top 5 states are:\")\n",
    "c2 = c1.head(5)\n",
    "print(c2)\n",
    "print(\"\\nTop 10 states covers\", round(c2.sum()/customers.shape[0]*100,1),\"percent of all the orders.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "c2.plot(kind=\"bar\",rot=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Orders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "orders.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "orders.info()\n",
    "customers.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "orders.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "orders_mod = orders.copy()\n",
    "orders_mod[\"order_purchase_timestamp\"] = pd.to_datetime(orders[\"order_purchase_timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "orders_mod[\"order_delivered_carrier_date\"] = pd.to_datetime(orders[\"order_delivered_carrier_date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "orders_mod[\"order_delivered_customer_date\"] = pd.to_datetime(orders[\"order_delivered_customer_date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "orders_mod[\"order_estimated_delivery_date\"] = pd.to_datetime(orders[\"order_estimated_delivery_date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "orders_mod.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "orders_mod.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##Viz on when purchases are made during period in dataset.\n",
    "counts = orders_mod.set_index(\"order_purchase_timestamp\").groupby(pd.Grouper(freq='D')).count()\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.gca()\n",
    "counts.plot(y = \"order_id\", use_index=True, ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##Identifies orderstatus distribution\n",
    "orderstatus = orders[\"order_status\"].nunique()\n",
    "o1 = orders.groupby('order_status')['customer_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",orderstatus,\"unique order_status in the dataset.\")\n",
    "o2 = o1.head(8)\n",
    "print(o2)\n",
    "o3 = o1.head(1)\n",
    "print(\"\\nDelivered status covers\", round(o3.sum()/orders.shape[0]*100,1),\"percent of all the orders.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Order Reviews"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reviews.info()\n",
    "reviews.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reviews.isnull().values.any()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Determine how many missing data instances\n",
    "reviews.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Address missing data - we can see that there is a review score but not necessarily a comment or a title. Should we make it \"none?\"\n",
    "\n",
    "reviews.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Items"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "items.info()\n",
    "items.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sellerinfo = items[\"seller_id\"].nunique()\n",
    "o1 = items.groupby('seller_id')['order_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",items,\"unique items in the dataset.\")\n",
    "o2 = o1.head(10)\n",
    "print(o2)\n",
    "\n",
    "print(\"\\nTop 10 items covers\", round(o2.sum()/orders.shape[0]*100,1),\"percent of all the orders.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sellers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sellers.info()\n",
    "sellers.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sellerstatus = sellers[\"seller_id\"].nunique()\n",
    "o1 = sellers.groupby('seller_city')['seller_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",sellerstatus,\"unique sellers in the dataset.\")\n",
    "o2 = o1.head(8)\n",
    "print(o2)\n",
    "\n",
    "print(\"\\nTop Seller by city covers\", round(o2.sum()/orders.shape[0]*100,1),\"percent of all the sellers.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sellerstatus = sellers[\"seller_id\"].nunique()\n",
    "o1 = sellers.groupby('seller_state')['seller_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",sellerstatus,\"unique sellers in the dataset.\")\n",
    "o2 = o1.head(8)\n",
    "print(o2)\n",
    "\n",
    "print(\"\\nTop Sellers by state represents\", round(o2.sum()/orders.shape[0]*100,1),\"percent of all the sellers.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Products"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "products.info()\n",
    "products.isnull().sum()\n",
    "# need to fix missing data 610 is the same entry but missing description. 2 items also missing (1 competely missing all except ID\n",
    "#other one is just missing weight, lenght, height, width) Dtypes changed from float64 to object as a result of replacing NA\n",
    "products[\"product_category_name\"].fillna(\"None\", inplace = True)\n",
    "products[\"product_name_lenght\"].fillna(\"None\", inplace = True)\n",
    "products[\"product_description_lenght\"].fillna(\"None\", inplace = True)\n",
    "products[\"product_photos_qty\"].fillna(\"None\", inplace = True)\n",
    "products[\"product_weight_g\"].fillna(\"0\", inplace = True)\n",
    "products[\"product_length_cm\"].fillna(\"0\", inplace = True)\n",
    "products[\"product_height_cm\"].fillna(\"0\", inplace = True)\n",
    "products[\"product_width_cm\"].fillna(\"0\", inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "products.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "most_product=df.groupby('product_category_name_english').aggregate({'order_id':'count'}).rename(columns={'order_id':'order_count'}).sort_values(by='order_count',ascending=False).reset_index()\n",
    "most_product.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Visualising top 10 most bought product categories:\n",
    "sns.barplot(x='product_category_name_english',y='order_count',data=most_product[:10],color=\"green\")\n",
    "plt.xlabel(\"Product Category\")\n",
    "plt.ylabel(\"Number of orders\")\n",
    "plt.title(\"Most bought product categories\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prodcat= df[\"product_id\"].nunique()\n",
    "o1 = df.groupby('product_category_name_english')['product_id'].nunique().sort_values(ascending=False)\n",
    "print(\"There are\",prodcat,\"unique products in the dataset.\")\n",
    "o2 = o1.head(10)\n",
    "print(o2)\n",
    "\n",
    "print(\"\\nTop 10 Products by category represent\", round(o2.sum()/orders.shape[0]*100,1),\"percent of all the products.\")\n",
    "plt.figure(figsize=(16,8))\n",
    "o2.plot(kind=\"bar\",rot=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Payment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "payments.info()\n",
    "payments.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Categories"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categories.info()\n",
    "categories.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")# NLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# translated Comments to English\n",
    "translated = pd.read_csv('reviews_MASTERLOW.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "english"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                                                Terrible\n",
       "1                                 The piece did not serve\n",
       "2       Missed 1 product and those receiving 1 broken ...\n",
       "3       here you are describing as delivered only unti...\n",
       "4       Canceled my purchase one day before delivery, ...\n",
       "                              ...                        \n",
       "1868    The chair came with factory defect, a loose to...\n",
       "1869                     My product came spoiled and bad.\n",
       "1870     As soon as receiving product I evaluate positive\n",
       "1871    The product was not delivered, the company doe...\n",
       "1872    My opinion is that I bought the product it had...\n",
       "Name: English, Length: 1873, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# we are going to work with only reviews dataset\n",
    "#reviews= reviews.dropna()\n",
    "#reviews.head(100)\n",
    "\n",
    "\n",
    "english = translated['English']\n",
    "# replace numbers of words\n",
    "english = english.apply(lambda t: re.sub(r\"(\\d+)\", lambda x: num2words(int(x.group(0))), str(t)))\n",
    "# replace special characters\n",
    "english = english.apply(lambda t: re.sub(r\"[^a-zA-Z0-9]+\", ' ', str(t)))\n",
    "# make all letters in a lower case\n",
    "english = english.apply(lambda t: str(t).lower())\n",
    "\n",
    "# tokenize text and remove stop words\n",
    "tokenized_reviews = english.apply(lambda t: word_tokenize(t))\n",
    "tokenized_reviews = tokenized_reviews.apply(lambda t: remove_stop_words(t))\n",
    "\n",
    "# spell check and stemming\n",
    "tokenized_reviews = tokenized_reviews.apply(lambda t: spell_and_stem_words(t))\n",
    "\n",
    "#tokenized_reviews.head(100)\n",
    "\n",
    "reviews_text = tokenized_reviews.apply(lambda t: \" \".join(t))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "''''\n",
    "we are going to work with only reviews dataset\n",
    "reviews = reviews.dropna()\n",
    "#reviews.head(100)\n",
    "\n",
    "reviews_only = reviews[reviews['review_score'] == 1]\n",
    "reviews_only = reviews_only['review_comment_message']\n",
    "# replace numbers of words\n",
    "reviews_only = reviews_only.apply(lambda t: re.sub(r\"(\\d+)\", lambda x: num2words(int(x.group(0))), t))\n",
    "# replace special characters\n",
    "reviews_only = reviews_only.apply(lambda t: re.sub('[^A-zÀ-ú\\s]/gi', ' ', t))\n",
    "# make all letters in a lower case\n",
    "reviews_only = reviews_only.apply(lambda t: t.lower())\n",
    "\n",
    "# tokenize text and remove stop words\n",
    "tokenized_reviews = reviews_only.apply(lambda t: word_tokenize(t))\n",
    "tokenized_reviews = tokenized_reviews.apply(lambda t: remove_stop_words(t))\n",
    "\n",
    "# spell check and stemming\n",
    "tokenized_reviews = tokenized_reviews.apply(lambda t: spell_and_stem_words(t))\n",
    "\n",
    "#tokenized_reviews.head(100)\n",
    "\n",
    "reviews_text = tokenized_reviews.apply(lambda t: \" \".join(t))\n",
    "'''''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# feature matrix\n",
    "# creating the feature matrix\n",
    "matrix = CountVectorizer(max_features=10000, ngram_range=(2, 2))\n",
    "X = matrix.fit_transform(reviews_text).toarray()\n",
    "matrix.vocabulary_\n",
    "#\n",
    "pd.set_option('display.max_rows', None)\n",
    "phrases = pd.DataFrame()\n",
    "phrases['phrases'] = matrix.get_feature_names()\n",
    "phrases['frequency'] = X.sum(axis=0) \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "#X.sum(axis=0) \n",
    "#phrases['frequency'] = X.sum(axis=0) \n",
    "#del phrases['English']\n",
    "phrases['English'] = ''\n",
    "#phrases['English'] = np.NaN\n",
    "phrases.info()\n",
    "#len(phrases)\n",
    "phrases.to_csv(\"phrases_eng_2_2.csv\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   phrases    10000 non-null  object\n",
      " 1   frequency  10000 non-null  int64 \n",
      " 2   English    10000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from googletrans import Translator\n",
    "import time\n",
    "\n",
    "translator = Translator()\n",
    "translator.raise_Exception = True\n",
    "\n",
    "#mini-batch loop. Loops 200 at a time. Hit failures with the translate API, switched to the slow iterrows loop below\n",
    "#for i in range(0, len(reviews_low), 200):\n",
    "    #print(i)\n",
    "    #a = reviews_low.iloc[i:i+199]\n",
    "    #reviews_low['English']=a['review_comment_message'].apply(translator.translate, src='pt', dest='en').apply(getattr, args=('text',))\n",
    "\n",
    "# row by row to handle when API limits are hit...not the best performance...can probably add the try/except to the mini-batch above for better performance, assuming it calls the google API in bulk\n",
    "for i, row in phrases.iterrows():\n",
    "    # Skip rows that were successful from previous attempts\n",
    "    # Blank text also seems to throw an error in the translator\n",
    "    if (pd.isnull(row['English']) or row['English'] == '') and not pd.isnull(row['phrases']) and row['phrases'].strip() != '':\n",
    "        try:\n",
    "            #getattr is to retrieve the object value for 'text', returns None if 'text' is not in the object\n",
    "            phrases.at[i, 'English'] = getattr(translator.translate(row['phrases'], src='pt', dest='en'), 'text')\n",
    "        # Most likely the 429 status code error from too many attempts\n",
    "        except Exception as e:\n",
    "            print('Error on {}: {}'.format(i, row['phrases']))\n",
    "            print(e)\n",
    "            print('pausing for 1min...')\n",
    "            time.sleep(60)\n",
    "            print('trying again...')\n",
    "            phrases.at[i, 'English'] = getattr(translator.translate(row['phrases'], src='pt', dest='en'), 'text')\n",
    "            print('Success! Moving on.')\n",
    "\n",
    "\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "phrases.to_csv(\"phrases_low_1-1.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}